<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MAYA - AI Assistant</title>
    <link href="https://fonts.googleapis.com/css2?family=Exo+2:wght@300;400;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
        :root { --primary: #00f2ff; --secondary: #ff0055; --bg: #050505; }
        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Exo 2', sans-serif; }
        
        body, html { 
            width: 100%; height: 100%; 
            background-color: var(--bg); color: white; 
            overflow: hidden; 
        }

        /* App Container */
        .app-container {
            width: 100vw; height: 100vh;
            background: radial-gradient(circle at center, #1a1a1a, #000);
            display: flex; flex-direction: column;
            align-items: center; justify-content: space-between;
            padding: 60px 20px;
            position: relative;
        }

        /* Header - Name Badge */
        .ai-badge {
            background: rgba(0, 242, 255, 0.05); color: var(--primary);
            border: 1px solid var(--primary);
            padding: 10px 35px; border-radius: 40px;
            font-weight: 700; font-size: 18px; letter-spacing: 3px;
            box-shadow: 0 0 25px rgba(0, 242, 255, 0.3);
            text-transform: uppercase;
        }

        /* 3D Orb Animation */
        .orb-wrapper {
            position: relative; width: 280px; height: 280px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 200px; height: 200px;
            background: linear-gradient(135deg, var(--primary), #005bea);
            border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: breathe 4s ease-in-out infinite;
            box-shadow: 0 0 80px rgba(0, 212, 255, 0.4);
            transition: all 0.3s ease;
        }

        /* Rings around Orb */
        .ring {
            position: absolute; border-radius: 50%;
            border: 1px solid rgba(255, 255, 255, 0.1);
            animation: rotate 10s linear infinite;
        }
        .r1 { width: 260px; height: 260px; border-top: 2px solid var(--primary); animation-duration: 4s; }
        .r2 { width: 320px; height: 320px; border-bottom: 2px solid var(--secondary); animation-duration: 7s; animation-direction: reverse; }

        @keyframes breathe {
            0%, 100% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.08); opacity: 1; box-shadow: 0 0 100px rgba(0, 212, 255, 0.7); }
        }
        @keyframes rotate { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        /* Text Area */
        .content { text-align: center; max-width: 700px; z-index: 10; margin-top: -30px; }
        #status-text { font-size: 24px; font-weight: 700; color: #fff; margin-bottom: 12px; text-shadow: 0 0 10px rgba(255,255,255,0.3); }
        #ai-reply { 
            color: #d0d0d0; font-size: 19px; line-height: 1.6; 
            min-height: 60px; font-weight: 300;
        }

        /* Controls */
        .bottom-nav {
            width: 100%; max-width: 400px;
            display: flex; justify-content: space-evenly; align-items: center;
            margin-bottom: 30px;
        }
        
        /* Mic Button Styling */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 80px; height: 80px; background: var(--bg);
            border: 2px solid var(--primary);
            border-radius: 50%; font-size: 28px;
            color: var(--primary); cursor: pointer; z-index: 5;
            box-shadow: 0 0 20px rgba(0, 242, 255, 0.2);
            transition: 0.3s;
        }
        .mic-btn:hover { background: var(--primary); color: #000; box-shadow: 0 0 40px var(--primary); }

        /* Active/Speaking States */
        .speaking .orb { background: linear-gradient(135deg, #ff0055, #ff5e00); box-shadow: 0 0 90px rgba(255, 0, 85, 0.6); }
        .listening .mic-btn { background: var(--secondary); border-color: var(--secondary); color: white; animation: pulseRed 1.5s infinite; }

        @keyframes pulseRed { 0% { transform: scale(1); box-shadow: 0 0 0 rgba(255,0,85,0.7); } 70% { transform: scale(1.1); box-shadow: 0 0 30px rgba(255,0,85,0); } 100% { transform: scale(1); } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">MAYA AI</div>

        <div class="orb-wrapper">
            <div class="ring r1"></div>
            <div class="ring r2"></div>
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, I am Maya</p>
            <p id="ai-reply">Tap the microphone to speak.</p>
        </div>

        <div class="bottom-nav">
            <div class="mic-box" id="micWrapper">
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
        </div>
    </div>

    <script>
        // --- CONFIGURATION ---
        const API_KEY = "AIzaSyA0CTFfWNXIEOq-lQdPtqMUHv64IkAvmWM"; // New Key
        const ASSISTANT_NAME = "Maya";

        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const orb = document.getElementById('orb');
        const mainApp = document.getElementById('mainApp');

        // Setup Speech Recognition
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; // Hinglish
            recognition.continuous = false;
        } else {
            aiReply.innerText = "Please use Google Chrome for Voice features.";
        }

        // --- 1. SPEAK FUNCTION (Voice Logic) ---
        function speak(text, isGreeting = false) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            
            // Try to select a Female Hindi/English voice
            const voices = window.speechSynthesis.getVoices();
            let preferredVoice = voices.find(v => v.name.includes('Google हिन्दी') || v.name.includes('Hindi India'));
            
            // Fallback to any female voice if Hindi not found
            if (!preferredVoice) {
                preferredVoice = voices.find(v => v.name.includes('Female') || v.name.includes('Samantha'));
            }

            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.pitch = 1.1; // Slightly higher pitch for female voice
            utterance.rate = 1.0;  // Normal speed

            // Visual effects when speaking
            utterance.onstart = () => { mainApp.classList.add('speaking'); };
            
            utterance.onend = () => { 
                mainApp.classList.remove('speaking'); 
                // Agar ye greeting thi ("Haan sir boliye"), to ab mic on karo
                if (isGreeting) {
                    startListeningActual();
                }
            };

            window.speechSynthesis.speak(utterance);
        }

        // --- 2. START LISTENING FLOW ---
        startBtn.addEventListener('click', () => {
            // Step 1: Maya speaks first
            statusText.innerText = "Maya is Active...";
            speak("Haan Sir, boliye", true); // Pass true to trigger mic after speaking
        });

        function startListeningActual() {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening...";
                    aiReply.innerText = "Listening...";
                } catch(e) {
                    console.log("Mic already active");
                }
            }
        }

        // --- 3. GEMINI AI INTEGRATION ---
        async function getGeminiResponse(userPrompt) {
            statusText.innerText = "Maya is thinking...";
            
            const systemPrompt = `You are MAYA, a highly intelligent, polite, and advanced female AI assistant. 
            Your creator is the user. 
            Always address the user as 'Sir'. 
            Reply in Hinglish (Mix of Hindi & English). 
            Keep answers short, crisp, and human-like. 
            User said: "${userPrompt}"`;

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ contents: [{ parts: [{ text: systemPrompt }] }] })
                });

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const answer = data.candidates[0].content.parts[0].text;
                    // Clean asterisks if Gemini adds them
                    const cleanAnswer = answer.replace(/\*/g, '');
                    
                    statusText.innerText = "Maya says:";
                    aiReply.innerText = cleanAnswer;
                    speak(cleanAnswer);
                } else {
                    speak("Maaf kijiye Sir, main samajh nahi payi.");
                }

            } catch (err) {
                statusText.innerText = "Error";
                aiReply.innerText = "Network issue, Sir.";
                speak("Sir, internet connection check kijiye.");
            }
        }

        // --- 4. RECOGNITION EVENTS ---
        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                
                statusText.innerText = "You said:";
                aiReply.innerText = transcript;

                // Handle commands
                if (transcript.toLowerCase().includes("time") || transcript.includes("samay")) {
                    const time = new Date().toLocaleTimeString('en-US', {hour:'numeric', minute:'numeric', hour12:true});
                    const reply = `Sir, abhi ${time} ho raha hai.`;
                    aiReply.innerText = reply;
                    speak(reply);
                } 
                else if (transcript.toLowerCase().includes("kaun ho") || transcript.toLowerCase().includes("who are you")) {
                    const reply = "Main Maya hoon Sir, aapki personal AI assistant.";
                    aiReply.innerText = reply;
                    speak(reply);
                }
                else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Inactive";
                // speak("Kuch sunayi nahi diya Sir.");
            };
        }

        // Load voices initially
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* Mic Button */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 90px; height: 90px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 32px;
            color: #000; cursor: pointer; z-index: 5;
            box-shadow: 0 0 30px rgba(0, 212, 255, 0.5);
            transition: transform 0.2s;
        }
        .mic-btn:active { transform: scale(0.95); }
        
        /* Active State Effects */
        .listening .mic-btn { animation: pulseRed 1.5s infinite; background: #ff4b4b; box-shadow: 0 0 30px rgba(255, 75, 75, 0.5); }
        .processing .orb { animation: spin 1s linear infinite; background: linear-gradient(135deg, #ff9a9e, #fecfef); }

        @keyframes pulseRed { 0% { transform: scale(1); } 50% { transform: scale(1.1); } 100% { transform: scale(1); } }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir</p>
            <p id="ai-reply">Main aapki kaise madad kar sakta hoon?</p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-gear"></i></button>
        </div>
    </div>

    <script>
        // WORKING GOOGLE API KEY (Aapki Key)
        const API_KEY = "AIzaSyA0CTFfWNXIEOq-lQdPtqMUHv64IkAvmWM";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        // Browser support check
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; // Hinglish samajhne ke liye
            recognition.continuous = false;
        } else {
            alert("Sir, please Chrome browser use karein.");
        }

        // --- Voice Logic (Professional Assistant) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            // Google Hindi Voice prefer karein
            const preferredVoice = voices.find(v => v.lang.includes('hi') || v.name.includes('Google'));
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic (Corrected Model) ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing...";

            // Assistant Persona Setup
            const systemPrompt = `You are a highly intelligent and polite Personal AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in a mix of Hindi and English (Hinglish). 
            Be concise, helpful, and friendly.
            User said: "${prompt}"`;

            // Using 'gemini-pro' (Most Stable Model for this Key)
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    throw new Error("API Limit or Network Issue");
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                    statusText.innerText = "Reply:";
                } else {
                    aiReply.innerText = "Sorry Sir, I didn't get that.";
                    speak("Sorry Sir, I didn't get that.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Connection Error";
                aiReply.innerText = "Sir, internet ya API mein kuch dikkat hai.";
                speak("Sir, connection error aa raha hai.");
            }
            mainApp.classList.remove('processing');
        }

        // --- Mic Interaction ---
        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening...";
                    aiReply.innerText = "";
                } catch(e) { 
                    recognition.stop();
                    micWrapper.classList.remove('listening');
                }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You said:";
                aiReply.innerText = transcript;

                // Simple Local Commands
                if(transcript.toLowerCase().includes('time') || transcript.includes('samay') || transcript.includes('baj')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi ${time} ho raha hai.`;
                    setTimeout(() => {
                        aiReply.innerText = msg;
                        speak(msg);
                    }, 500);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Try Again";
                aiReply.innerText = "Mic Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        // Voice Loader
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, main online hoon.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // API Key
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available in this browser.");
        }

        // --- Voice Logic ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            // Assistant Persona
            const systemPrompt = `You are a helpful and polite AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            Keep answers short and clear.
            User said: "${prompt}"`;

            // MODEL CHANGED TO 'gemini-pro' (Stable Version)
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error.message);
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                } else {
                    aiReply.innerText = "Sorry Sir, I didn't catch that.";
                    speak("Sorry Sir, I didn't catch that.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Error: " + err.message;
                aiReply.innerText = "Sir, connection mein issue aa raha hai.";
                speak("Sir, connection mein issue aa raha hai.");
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
