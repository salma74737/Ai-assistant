<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MAYA - Advanced AI</title>
    <link href="https://fonts.googleapis.com/css2?family=Rajdhani:wght@300;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
        :root { --neon-blue: #00f3ff; --neon-pink: #bc13fe; --bg: #020202; }
        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Rajdhani', sans-serif; }
        
        body { 
            background: var(--bg); color: white; height: 100vh; overflow: hidden; 
            display: flex; flex-direction: column; align-items: center; justify-content: center;
        }

        /* HUD Design */
        .hud-container {
            position: absolute; top: 0; left: 0; width: 100%; height: 100%;
            pointer-events: none; z-index: 1;
            background: radial-gradient(circle, transparent 60%, black 100%),
                        linear-gradient(rgba(0, 243, 255, 0.03) 1px, transparent 1px),
                        linear-gradient(90deg, rgba(0, 243, 255, 0.03) 1px, transparent 1px);
            background-size: 100% 100%, 40px 40px, 40px 40px;
        }

        /* Central Orb (The Brain) */
        .brain-core {
            position: relative; width: 250px; height: 250px;
            display: flex; justify-content: center; align-items: center;
            z-index: 10; margin-bottom: 30px;
        }
        .core-circle {
            width: 180px; height: 180px; background: black;
            border-radius: 50%; border: 2px solid var(--neon-blue);
            box-shadow: 0 0 50px var(--neon-blue), inset 0 0 30px var(--neon-blue);
            display: flex; justify-content: center; align-items: center;
            animation: pulseCore 3s infinite ease-in-out;
        }
        .wave {
            position: absolute; width: 100%; height: 100%; border-radius: 50%;
            border: 1px solid rgba(0, 243, 255, 0.3);
            animation: ripples 2s linear infinite;
        }
        .wave:nth-child(2) { animation-delay: 0.5s; }
        .wave:nth-child(3) { animation-delay: 1s; }

        @keyframes pulseCore { 0%, 100% { transform: scale(1); opacity: 0.8; } 50% { transform: scale(1.05); opacity: 1; box-shadow: 0 0 80px var(--neon-blue); } }
        @keyframes ripples { 0% { width: 180px; height: 180px; opacity: 1; } 100% { width: 350px; height: 350px; opacity: 0; } }

        /* Text UI */
        .ui-text { text-align: center; z-index: 20; width: 90%; max-width: 600px; }
        .maya-title { 
            font-size: 24px; letter-spacing: 5px; color: var(--neon-blue); 
            margin-bottom: 10px; text-transform: uppercase; font-weight: 700;
        }
        #status { font-size: 18px; color: #888; margin-bottom: 20px; }
        #response-box { 
            min-height: 80px; font-size: 20px; line-height: 1.5; 
            color: #fff; text-shadow: 0 0 5px rgba(255,255,255,0.5);
        }

        /* Mic Button */
        .controls { position: absolute; bottom: 50px; z-index: 30; }
        .mic-btn {
            width: 80px; height: 80px; border-radius: 50%;
            background: rgba(0,0,0,0.6); border: 2px solid var(--neon-blue);
            color: var(--neon-blue); font-size: 30px; cursor: pointer;
            box-shadow: 0 0 20px rgba(0, 243, 255, 0.2);
            transition: 0.3s;
        }
        .mic-btn:hover { background: var(--neon-blue); color: #000; box-shadow: 0 0 50px var(--neon-blue); }
        .mic-btn.active { border-color: var(--neon-pink); color: var(--neon-pink); animation: shake 0.5s infinite; }

        @keyframes shake { 0% { transform: translate(1px, 1px) rotate(0deg); } 50% { transform: translate(-1px, -2px) rotate(-1deg); } 100% { transform: translate(1px, -1px) rotate(1deg); } }

        /* Processing State */
        .processing .core-circle { border-color: var(--neon-pink); box-shadow: 0 0 60px var(--neon-pink); }
    </style>
</head>
<body>

    <div class="hud-container"></div>

    <div class="brain-core" id="brain">
        <div class="wave"></div>
        <div class="wave"></div>
        <div class="wave"></div>
        <div class="core-circle">
            <i class="fa-solid fa-microchip" style="font-size: 50px; color: white;"></i>
        </div>
    </div>

    <div class="ui-text">
        <div class="maya-title">MAYA A.I. SYSTEM</div>
        <p id="status">Online & Ready</p>
        <p id="response-box">Tap the microphone to Initialize.</p>
    </div>

    <div class="controls">
        <button class="mic-btn" id="micBtn"><i class="fa-solid fa-microphone"></i></button>
    </div>

    <script>
        // --- ADVANCED CONFIGURATION ---
        const API_KEY = "AIzaSyA0CTFfWNXIEOq-lQdPtqMUHv64IkAvmWM"; 
        // Using Gemini 1.5 Flash (Faster & Smarter)
        const API_URL = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`;
        
        const micBtn = document.getElementById('micBtn');
        const statusText = document.getElementById('status');
        const responseBox = document.getElementById('response-box');
        const brain = document.getElementById('brain');

        // Speech Setup
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        const recognition = new SpeechRecognition();
        recognition.lang = 'hi-IN'; // Hinglish Support
        recognition.continuous = false;

        // --- INTELLIGENT VOICE OUTPUT ---
        function speak(text, afterSpeakCallback = null) {
            window.speechSynthesis.cancel(); // Stop previous audio
            const utterance = new SpeechSynthesisUtterance(text);
            
            // Voice Selection (Prefer Google Hindi/English Female)
            const voices = window.speechSynthesis.getVoices();
            const voice = voices.find(v => v.name.includes('Google हिन्दी') || v.name.includes('Hindi') || v.lang.includes('hi'));
            if (voice) utterance.voice = voice;
            
            utterance.rate = 1; 
            utterance.pitch = 1.1;

            utterance.onend = () => {
                if(afterSpeakCallback) afterSpeakCallback();
            };

            window.speechSynthesis.speak(utterance);
        }

        // --- BUTTON CLICK HANDLER ---
        micBtn.addEventListener('click', () => {
            micBtn.classList.add('active');
            statusText.innerText = "Initializing...";
            
            // 1. Maya Speaks First
            speak("Haan Sir, boliye", () => {
                // 2. Then Mic Turns On
                try {
                    recognition.start();
                    statusText.innerText = "Listening...";
                    responseBox.innerText = "Listening...";
                } catch (e) {
                    console.error(e);
                    micBtn.classList.remove('active');
                }
            });
        });

        // --- HANDLE USER VOICE INPUT ---
        recognition.onresult = async (event) => {
            micBtn.classList.remove('active');
            const userCommand = event.results[0][0].transcript;
            
            statusText.innerText = "Processing Data...";
            responseBox.innerText = `"${userCommand}"`;
            brain.classList.add('processing');

            // --- LOCAL INTELLIGENCE (Time/Date - Instant Reply) ---
            const lowerCmd = userCommand.toLowerCase();
            
            if (lowerCmd.includes("time") || lowerCmd.includes("samay") || lowerCmd.includes("baj")) {
                const now = new Date();
                const timeString = now.toLocaleTimeString('en-US', { hour: 'numeric', minute: 'numeric', hour12: true });
                const reply = `Sir, abhi ${timeString} ho raha hai.`;
                finishRequest(reply);
                return;
            }
            
            if (lowerCmd.includes("date") || lowerCmd.includes("taarikh")) {
                const dateString = new Date().toLocaleDateString('en-IN', { weekday: 'long', year: 'numeric', month: 'long', day: 'numeric' });
                const reply = `Sir, aaj ${dateString} hai.`;
                finishRequest(reply);
                return;
            }

            // --- CLOUD INTELLIGENCE (Gemini API) ---
            await fetchGeminiResponse(userCommand);
        };

        // --- GEMINI API "ADVANCED BRAIN" ---
        async function fetchGeminiResponse(prompt) {
            // Context Injection (Giving the AI a brain)
            const currentTime = new Date().toLocaleString();
            
            const systemInstruction = `
            You are MAYA, an advanced AI Assistant. 
            Current Date & Time: ${currentTime}.
            User Role: Addressed as 'Sir'.
            Language: Hinglish (Hindi + English Mix).
            Personality: Intelligent, Precise, and Polite.
            Instruction: Give short, direct answers. Do not use markdown stars (*). 
            If asked about time/date, use the Current Date & Time provided above.
            `;

            try {
                const response = await fetch(API_URL, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{
                            parts: [{ text: systemInstruction + "\nUser Question: " + prompt }]
                        }],
                        generationConfig: {
                            temperature: 0.7,
                            maxOutputTokens: 100 // Keep answers concise for voice
                        }
                    })
                });

                const data = await response.json();
                
                if (data.error) {
                    throw new Error(data.error.message);
                }

                const aiResponse = data.candidates[0].content.parts[0].text;
                finishRequest(aiResponse);

            } catch (error) {
                console.error("Brain Error:", error);
                finishRequest("Sir, server connect nahi ho raha. Internet check karein.");
            }
        }

        // --- CLEANUP & SPEAK RESULT ---
        function finishRequest(text) {
            brain.classList.remove('processing');
            statusText.innerText = "Maya says:";
            
            // Remove markdown symbols just in case
            const cleanText = text.replace(/\*/g, '').trim();
            
            responseBox.innerText = cleanText;
            speak(cleanText);
        }

        recognition.onerror = () => {
            micBtn.classList.remove('active');
            statusText.innerText = "Error";
            brain.classList.remove('processing');
        };
        
        // Load Voices
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>            text-transform: uppercase;
        }

        /* 3D Orb Animation */
        .orb-wrapper {
            position: relative; width: 280px; height: 280px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 200px; height: 200px;
            background: linear-gradient(135deg, var(--primary), #005bea);
            border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: breathe 4s ease-in-out infinite;
            box-shadow: 0 0 80px rgba(0, 212, 255, 0.4);
            transition: all 0.3s ease;
        }

        /* Rings around Orb */
        .ring {
            position: absolute; border-radius: 50%;
            border: 1px solid rgba(255, 255, 255, 0.1);
            animation: rotate 10s linear infinite;
        }
        .r1 { width: 260px; height: 260px; border-top: 2px solid var(--primary); animation-duration: 4s; }
        .r2 { width: 320px; height: 320px; border-bottom: 2px solid var(--secondary); animation-duration: 7s; animation-direction: reverse; }

        @keyframes breathe {
            0%, 100% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.08); opacity: 1; box-shadow: 0 0 100px rgba(0, 212, 255, 0.7); }
        }
        @keyframes rotate { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

        /* Text Area */
        .content { text-align: center; max-width: 700px; z-index: 10; margin-top: -30px; }
        #status-text { font-size: 24px; font-weight: 700; color: #fff; margin-bottom: 12px; text-shadow: 0 0 10px rgba(255,255,255,0.3); }
        #ai-reply { 
            color: #d0d0d0; font-size: 19px; line-height: 1.6; 
            min-height: 60px; font-weight: 300;
        }

        /* Controls */
        .bottom-nav {
            width: 100%; max-width: 400px;
            display: flex; justify-content: space-evenly; align-items: center;
            margin-bottom: 30px;
        }
        
        /* Mic Button Styling */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 80px; height: 80px; background: var(--bg);
            border: 2px solid var(--primary);
            border-radius: 50%; font-size: 28px;
            color: var(--primary); cursor: pointer; z-index: 5;
            box-shadow: 0 0 20px rgba(0, 242, 255, 0.2);
            transition: 0.3s;
        }
        .mic-btn:hover { background: var(--primary); color: #000; box-shadow: 0 0 40px var(--primary); }

        /* Active/Speaking States */
        .speaking .orb { background: linear-gradient(135deg, #ff0055, #ff5e00); box-shadow: 0 0 90px rgba(255, 0, 85, 0.6); }
        .listening .mic-btn { background: var(--secondary); border-color: var(--secondary); color: white; animation: pulseRed 1.5s infinite; }

        @keyframes pulseRed { 0% { transform: scale(1); box-shadow: 0 0 0 rgba(255,0,85,0.7); } 70% { transform: scale(1.1); box-shadow: 0 0 30px rgba(255,0,85,0); } 100% { transform: scale(1); } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">MAYA AI</div>

        <div class="orb-wrapper">
            <div class="ring r1"></div>
            <div class="ring r2"></div>
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, I am Maya</p>
            <p id="ai-reply">Tap the microphone to speak.</p>
        </div>

        <div class="bottom-nav">
            <div class="mic-box" id="micWrapper">
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
        </div>
    </div>

    <script>
        // --- CONFIGURATION ---
        const API_KEY = "AIzaSyA0CTFfWNXIEOq-lQdPtqMUHv64IkAvmWM"; // New Key
        const ASSISTANT_NAME = "Maya";

        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const orb = document.getElementById('orb');
        const mainApp = document.getElementById('mainApp');

        // Setup Speech Recognition
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; // Hinglish
            recognition.continuous = false;
        } else {
            aiReply.innerText = "Please use Google Chrome for Voice features.";
        }

        // --- 1. SPEAK FUNCTION (Voice Logic) ---
        function speak(text, isGreeting = false) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            
            // Try to select a Female Hindi/English voice
            const voices = window.speechSynthesis.getVoices();
            let preferredVoice = voices.find(v => v.name.includes('Google हिन्दी') || v.name.includes('Hindi India'));
            
            // Fallback to any female voice if Hindi not found
            if (!preferredVoice) {
                preferredVoice = voices.find(v => v.name.includes('Female') || v.name.includes('Samantha'));
            }

            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.pitch = 1.1; // Slightly higher pitch for female voice
            utterance.rate = 1.0;  // Normal speed

            // Visual effects when speaking
            utterance.onstart = () => { mainApp.classList.add('speaking'); };
            
            utterance.onend = () => { 
                mainApp.classList.remove('speaking'); 
                // Agar ye greeting thi ("Haan sir boliye"), to ab mic on karo
                if (isGreeting) {
                    startListeningActual();
                }
            };

            window.speechSynthesis.speak(utterance);
        }

        // --- 2. START LISTENING FLOW ---
        startBtn.addEventListener('click', () => {
            // Step 1: Maya speaks first
            statusText.innerText = "Maya is Active...";
            speak("Haan Sir, boliye", true); // Pass true to trigger mic after speaking
        });

        function startListeningActual() {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening...";
                    aiReply.innerText = "Listening...";
                } catch(e) {
                    console.log("Mic already active");
                }
            }
        }

        // --- 3. GEMINI AI INTEGRATION ---
        async function getGeminiResponse(userPrompt) {
            statusText.innerText = "Maya is thinking...";
            
            const systemPrompt = `You are MAYA, a highly intelligent, polite, and advanced female AI assistant. 
            Your creator is the user. 
            Always address the user as 'Sir'. 
            Reply in Hinglish (Mix of Hindi & English). 
            Keep answers short, crisp, and human-like. 
            User said: "${userPrompt}"`;

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ contents: [{ parts: [{ text: systemPrompt }] }] })
                });

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const answer = data.candidates[0].content.parts[0].text;
                    // Clean asterisks if Gemini adds them
                    const cleanAnswer = answer.replace(/\*/g, '');
                    
                    statusText.innerText = "Maya says:";
                    aiReply.innerText = cleanAnswer;
                    speak(cleanAnswer);
                } else {
                    speak("Maaf kijiye Sir, main samajh nahi payi.");
                }

            } catch (err) {
                statusText.innerText = "Error";
                aiReply.innerText = "Network issue, Sir.";
                speak("Sir, internet connection check kijiye.");
            }
        }

        // --- 4. RECOGNITION EVENTS ---
        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                
                statusText.innerText = "You said:";
                aiReply.innerText = transcript;

                // Handle commands
                if (transcript.toLowerCase().includes("time") || transcript.includes("samay")) {
                    const time = new Date().toLocaleTimeString('en-US', {hour:'numeric', minute:'numeric', hour12:true});
                    const reply = `Sir, abhi ${time} ho raha hai.`;
                    aiReply.innerText = reply;
                    speak(reply);
                } 
                else if (transcript.toLowerCase().includes("kaun ho") || transcript.toLowerCase().includes("who are you")) {
                    const reply = "Main Maya hoon Sir, aapki personal AI assistant.";
                    aiReply.innerText = reply;
                    speak(reply);
                }
                else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Inactive";
                // speak("Kuch sunayi nahi diya Sir.");
            };
        }

        // Load voices initially
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* Mic Button */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 90px; height: 90px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 32px;
            color: #000; cursor: pointer; z-index: 5;
            box-shadow: 0 0 30px rgba(0, 212, 255, 0.5);
            transition: transform 0.2s;
        }
        .mic-btn:active { transform: scale(0.95); }
        
        /* Active State Effects */
        .listening .mic-btn { animation: pulseRed 1.5s infinite; background: #ff4b4b; box-shadow: 0 0 30px rgba(255, 75, 75, 0.5); }
        .processing .orb { animation: spin 1s linear infinite; background: linear-gradient(135deg, #ff9a9e, #fecfef); }

        @keyframes pulseRed { 0% { transform: scale(1); } 50% { transform: scale(1.1); } 100% { transform: scale(1); } }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir</p>
            <p id="ai-reply">Main aapki kaise madad kar sakta hoon?</p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-gear"></i></button>
        </div>
    </div>

    <script>
        // WORKING GOOGLE API KEY (Aapki Key)
        const API_KEY = "AIzaSyA0CTFfWNXIEOq-lQdPtqMUHv64IkAvmWM";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        // Browser support check
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; // Hinglish samajhne ke liye
            recognition.continuous = false;
        } else {
            alert("Sir, please Chrome browser use karein.");
        }

        // --- Voice Logic (Professional Assistant) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            // Google Hindi Voice prefer karein
            const preferredVoice = voices.find(v => v.lang.includes('hi') || v.name.includes('Google'));
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic (Corrected Model) ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing...";

            // Assistant Persona Setup
            const systemPrompt = `You are a highly intelligent and polite Personal AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in a mix of Hindi and English (Hinglish). 
            Be concise, helpful, and friendly.
            User said: "${prompt}"`;

            // Using 'gemini-pro' (Most Stable Model for this Key)
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    throw new Error("API Limit or Network Issue");
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                    statusText.innerText = "Reply:";
                } else {
                    aiReply.innerText = "Sorry Sir, I didn't get that.";
                    speak("Sorry Sir, I didn't get that.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Connection Error";
                aiReply.innerText = "Sir, internet ya API mein kuch dikkat hai.";
                speak("Sir, connection error aa raha hai.");
            }
            mainApp.classList.remove('processing');
        }

        // --- Mic Interaction ---
        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening...";
                    aiReply.innerText = "";
                } catch(e) { 
                    recognition.stop();
                    micWrapper.classList.remove('listening');
                }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You said:";
                aiReply.innerText = transcript;

                // Simple Local Commands
                if(transcript.toLowerCase().includes('time') || transcript.includes('samay') || transcript.includes('baj')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi ${time} ho raha hai.`;
                    setTimeout(() => {
                        aiReply.innerText = msg;
                        speak(msg);
                    }, 500);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Try Again";
                aiReply.innerText = "Mic Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        // Voice Loader
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, main online hoon.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // API Key
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available in this browser.");
        }

        // --- Voice Logic ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            // Assistant Persona
            const systemPrompt = `You are a helpful and polite AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            Keep answers short and clear.
            User said: "${prompt}"`;

            // MODEL CHANGED TO 'gemini-pro' (Stable Version)
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error.message);
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                } else {
                    aiReply.innerText = "Sorry Sir, I didn't catch that.";
                    speak("Sorry Sir, I didn't catch that.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Error: " + err.message;
                aiReply.innerText = "Sir, connection mein issue aa raha hai.";
                speak("Sir, connection mein issue aa raha hai.");
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
