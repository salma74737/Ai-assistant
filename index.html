<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Assistant - Full Screen</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    
    <style>
        :root { --primary: #C1FF3D; --bg: #000000; }
        * { margin: 0; padding: 0; box-sizing: border-box; font-family: 'Inter', sans-serif; }
        
        body, html { 
            width: 100%; height: 100%; 
            background-color: var(--bg); color: white; 
            overflow: hidden; 
        }

        /* Full Screen UI Container */
        .app-container {
            width: 100vw; height: 100vh;
            background: radial-gradient(circle at top right, #1a1a1a, #000);
            display: flex; flex-direction: column;
            align-items: center; justify-content: space-between;
            padding: 60px 20px;
            position: relative;
        }

        /* Top Header */
        .ai-badge {
            background: var(--primary); color: black;
            padding: 10px 30px; border-radius: 40px;
            font-weight: 600; font-size: 16px;
            box-shadow: 0 0 30px rgba(193, 255, 61, 0.4);
        }

        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, main online hoon.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <!-- Script Type is Module to support Import -->
    <script type="module">
        // Import Bytez.js from CDN
        import Bytez from "https://esm.sh/bytez.js";

        const BYTEZ_KEY = "4c9373988a4f655b7427d6d785db5d93";
        let sdk;
        let model;

        // Initialize Bytez SDK
        try {
            sdk = new Bytez(BYTEZ_KEY);
            model = sdk.model("google/gemini-3-pro-preview");
            console.log("Bytez SDK Initialized");
        } catch(e) {
            console.error("SDK Init Error", e);
        }

        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available.");
        }

        // --- Voice Logic (Assistant Style) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Bytez AI Logic ---
        async function getBytezResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            // Persona Instruction appended to prompt
            const fullPrompt = `You are a helpful and polite AI Assistant. 
            Address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            User said: "${prompt}"`;

            try {
                if (!model) throw new Error("Model not initialized");

                const { error, output } = await model.run([
                    {
                        "role": "user",
                        "content": fullPrompt
                    }
                ]);

                if (error) {
                    throw new Error(error);
                }

                if (output) {
                    // Extracting text from output (handling different response formats)
                    let replyText = typeof output === 'string' ? output : (output[0]?.text || JSON.stringify(output));
                    
                    // Clean up if needed
                    aiReply.innerText = replyText;
                    speak(replyText);
                } else {
                    aiReply.innerText = "Sorry Sir, response nahi aaya.";
                    speak("Sorry Sir, response nahi aaya.");
                }

            } catch (err) {
                console.error("Bytez Error:", err);
                statusText.innerText = "API Error";
                aiReply.innerText = "Sir, connection error hai.";
                speak("Sir, connection error hai.");
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getBytezResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge" id="badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, system ready hai.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // API Configuration
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4"; 
        
        // DOM Elements
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const badge = document.getElementById('badge');
        const mainApp = document.getElementById('mainApp');

        // Check for Internet immediately
        if (!navigator.onLine) {
            statusText.innerText = "Warning: Internet disconnect hai.";
            badge.classList.add('error');
            badge.innerText = "OFFLINE";
        }

        // --- Speech Recognition Setup ---
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN';
            recognition.continuous = false;
        } else {
            alert("Aapka Browser Mic support nahi karta. Google Chrome use karein.");
        }

        // --- Human-Like Voice Output ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            // Select Hindi or Default voice
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices.find(v => v.name.includes('Google')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Robust AI Logic (Tries Multiple Models) ---
        async function getGeminiResponse(prompt) {
            if (!navigator.onLine) {
                const msg = "Sir, Internet connection nahi hai.";
                statusText.innerText = msg;
                speak(msg);
                return;
            }

            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";
            badge.innerText = "THINKING...";

            const systemPrompt = `You are a polite and smart AI Assistant. 
            Address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            Keep it short and conversational.
            User said: "${prompt}"`;

            // Try Primary Model (Flash - Faster)
            let success = await tryFetchModel("gemini-1.5-flash", systemPrompt);

            // If Primary fails, Try Backup (Pro - Stable)
            if (!success) {
                console.log("Switching to Backup Model...");
                success = await tryFetchModel("gemini-pro", systemPrompt);
            }

            if (!success) {
                badge.classList.add('error');
                badge.innerText = "ERROR";
                statusText.innerText = "API Error. Check Console.";
                aiReply.innerText = "Sir, server se connect nahi ho pa raha.";
                speak("Sir, server se connect nahi ho pa raha.");
            } else {
                badge.classList.remove('error');
                badge.innerText = "ONLINE";
            }
            mainApp.classList.remove('processing');
        }

        async function tryFetchModel(modelName, promptText) {
            try {
                const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelName}:generateContent?key=${API_KEY}`;
                
                const response = await fetch(url, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: promptText }] }]
                    })
                });

                if (!response.ok) {
                    throw new Error(`HTTP Error: ${response.status}`);
                }

                const data = await response.json();
                const text = data.candidates[0].content.parts[0].text;
                
                aiReply.innerText = text;
                speak(text);
                return true;

            } catch (err) {
                console.error(`Failed with ${modelName}:`, err);
                return false;
            }
        }

        // --- Event Listeners ---
        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { 
                    console.log("Mic restart");
                    recognition.stop();
                }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                // Local Time Command
                if(transcript.toLowerCase().includes('time') || transcript.includes('samay') || transcript.includes('baj')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                console.error(e);
                if (e.error === 'network') {
                    statusText.innerText = "Network Error (Mic)";
                } else {
                    statusText.innerText = "Error: " + e.error;
                }
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        // Initialize Voices
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, main online hoon.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // Using Google Key again because Bytez fails in browser
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available in this browser.");
        }

        // --- Voice Logic (Assistant Style) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic with Fallback ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            const systemPrompt = `You are a helpful and polite AI Assistant. 
            Address user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            User said: "${prompt}"`;

            // Try the main model first (Flash - Faster)
            let modelVersion = "gemini-1.5-flash";
            let success = await tryFetchModel(modelVersion, systemPrompt);

            // If Flash fails, try Pro (Stable)
            if (!success) {
                console.log("Flash failed, trying Pro...");
                modelVersion = "gemini-pro";
                success = await tryFetchModel(modelVersion, systemPrompt);
            }

            if (!success) {
                statusText.innerText = "API Error";
                aiReply.innerText = "Sir, Google API connect nahi ho raha. Key check karein.";
                speak("Sir, API mein dikkat hai.");
            }
            mainApp.classList.remove('processing');
        }

        async function tryFetchModel(model, promptText) {
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: promptText }] }]
                    })
                });

                if (!response.ok) throw new Error("Model request failed");

                const data = await response.json();
                const text = data.candidates[0].content.parts[0].text;
                aiReply.innerText = text;
                speak(text);
                return true;

            } catch (err) {
                console.error(`Error with ${model}:`, err);
                return false;
            }
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, main online hoon.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <!-- Script Type is Module to support Import -->
    <script type="module">
        // Import Bytez.js from CDN
        import Bytez from "https://esm.sh/bytez.js";

        const BYTEZ_KEY = "4c9373988a4f655b7427d6d785db5d93";
        let sdk;
        let model;

        // Initialize Bytez SDK
        try {
            sdk = new Bytez(BYTEZ_KEY);
            model = sdk.model("google/gemini-3-pro-preview");
            console.log("Bytez SDK Initialized");
        } catch(e) {
            console.error("SDK Init Error", e);
        }

        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available.");
        }

        // --- Voice Logic (Assistant Style) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Bytez AI Logic ---
        async function getBytezResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            // Persona Instruction appended to prompt
            const fullPrompt = `You are a helpful and polite AI Assistant. 
            Address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            User said: "${prompt}"`;

            try {
                if (!model) throw new Error("Model not initialized");

                const { error, output } = await model.run([
                    {
                        "role": "user",
                        "content": fullPrompt
                    }
                ]);

                if (error) {
                    throw new Error(error);
                }

                if (output) {
                    // Extracting text from output (handling different response formats)
                    let replyText = typeof output === 'string' ? output : (output[0]?.text || JSON.stringify(output));
                    
                    // Clean up if needed
                    aiReply.innerText = replyText;
                    speak(replyText);
                } else {
                    aiReply.innerText = "Sorry Sir, response nahi aaya.";
                    speak("Sorry Sir, response nahi aaya.");
                }

            } catch (err) {
                console.error("Bytez Error:", err);
                statusText.innerText = "API Error";
                aiReply.innerText = "Sir, connection error hai.";
                speak("Sir, connection error hai.");
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getBytezResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>        }

        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 300px; height: 300px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 220px; height: 220px;
            background: linear-gradient(135deg, #00d4ff, #005bea);
            border-radius: 50%;
            filter: blur(1px); z-index: 2;
            animation: breathe 4s ease-in-out infinite;
            box-shadow: 0 0 80px rgba(0, 212, 255, 0.4);
            transition: all 0.3s ease;
        }

        @keyframes breathe {
            0%, 100% { transform: scale(1); opacity: 0.8; }
            50% { transform: scale(1.05); opacity: 1; box-shadow: 0 0 100px rgba(0, 212, 255, 0.6); }
        }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; margin-top: -50px; }
        #status-text { font-size: 26px; font-weight: 600; color: #fff; margin-bottom: 10px; }
        #ai-reply { 
            color: #a0a0a0; font-size: 18px; line-height: 1.6; 
            min-height: 50px; font-weight: 300;
        }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 40px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.08); border: none;
            width: 60px; height: 60px; border-radius: 50%;
            color: white; font-size: 20px; cursor: pointer; 
            transition: 0.2s;
        }
        .icon-btn:hover { background: rgba(255, 255, 255, 0.2); }

        /* Mic Button */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 90px; height: 90px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 32px;
            color: #000; cursor: pointer; z-index: 5;
            box-shadow: 0 0 30px rgba(0, 212, 255, 0.5);
            transition: transform 0.2s;
        }
        .mic-btn:active { transform: scale(0.95); }
        
        /* Active State Effects */
        .listening .mic-btn { animation: pulseRed 1.5s infinite; background: #ff4b4b; box-shadow: 0 0 30px rgba(255, 75, 75, 0.5); }
        .processing .orb { animation: spin 1s linear infinite; background: linear-gradient(135deg, #ff9a9e, #fecfef); }

        @keyframes pulseRed { 0% { transform: scale(1); } 50% { transform: scale(1.1); } 100% { transform: scale(1); } }
        @keyframes spin { 0% { transform: rotate(0deg); } 100% { transform: rotate(360deg); } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir</p>
            <p id="ai-reply">Main aapki kaise madad kar sakta hoon?</p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-gear"></i></button>
        </div>
    </div>

    <script>
        // WORKING GOOGLE API KEY (Aapki Key)
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        // Browser support check
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; // Hinglish samajhne ke liye
            recognition.continuous = false;
        } else {
            alert("Sir, please Chrome browser use karein.");
        }

        // --- Voice Logic (Professional Assistant) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            // Google Hindi Voice prefer karein
            const preferredVoice = voices.find(v => v.lang.includes('hi') || v.name.includes('Google'));
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic (Corrected Model) ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing...";

            // Assistant Persona Setup
            const systemPrompt = `You are a highly intelligent and polite Personal AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in a mix of Hindi and English (Hinglish). 
            Be concise, helpful, and friendly.
            User said: "${prompt}"`;

            // Using 'gemini-pro' (Most Stable Model for this Key)
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    throw new Error("API Limit or Network Issue");
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                    statusText.innerText = "Reply:";
                } else {
                    aiReply.innerText = "Sorry Sir, I didn't get that.";
                    speak("Sorry Sir, I didn't get that.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Connection Error";
                aiReply.innerText = "Sir, internet ya API mein kuch dikkat hai.";
                speak("Sir, connection error aa raha hai.");
            }
            mainApp.classList.remove('processing');
        }

        // --- Mic Interaction ---
        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening...";
                    aiReply.innerText = "";
                } catch(e) { 
                    recognition.stop();
                    micWrapper.classList.remove('listening');
                }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You said:";
                aiReply.innerText = transcript;

                // Simple Local Commands
                if(transcript.toLowerCase().includes('time') || transcript.includes('samay') || transcript.includes('baj')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi ${time} ho raha hai.`;
                    setTimeout(() => {
                        aiReply.innerText = msg;
                        speak(msg);
                    }, 500);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Try Again";
                aiReply.innerText = "Mic Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        // Voice Loader
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, main online hoon.</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // API Key
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available in this browser.");
        }

        // --- Voice Logic ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            // Assistant Persona
            const systemPrompt = `You are a helpful and polite AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            Keep answers short and clear.
            User said: "${prompt}"`;

            // MODEL CHANGED TO 'gemini-pro' (Stable Version)
            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error.message);
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                } else {
                    aiReply.innerText = "Sorry Sir, I didn't catch that.";
                    speak("Sorry Sir, I didn't catch that.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Error: " + err.message;
                aiReply.innerText = "Sir, connection mein issue aa raha hai.";
                speak("Sir, connection mein issue aa raha hai.");
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi time ${time} ho raha hai.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI ASSISTANT ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Hello Sir, kaise madad karoon?</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // NEW API KEY ADDED
        const API_KEY = "AIzaSyDbOws7UuHzRJmGEodTZFSjwLT6vEz6rG4";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; 
        } else {
            alert("Mic support not available in this browser.");
        }

        // --- Voice Logic (Assistant Style) ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            // Try to find a clear voice
            const preferredVoice = voices.find(v => v.lang.includes('hi')) || voices[0];
            if (preferredVoice) utterance.voice = preferredVoice;
            
            utterance.rate = 1.0; 
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic (Assistant Persona) ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Processing Sir...";

            // "Assistant" System Prompt
            const systemPrompt = `You are a helpful and polite AI Assistant. 
            Always address the user as 'Sir'. 
            Reply in Hinglish (Hindi + English mix). 
            Keep answers short, professional yet natural.
            User said: "${prompt}"`;

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                if (!response.ok) {
                    const errorData = await response.json();
                    throw new Error(errorData.error.message);
                }

                const data = await response.json();
                
                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                } else {
                    aiReply.innerText = "Sorry Sir, mujhe samajh nahi aaya.";
                    speak("Sorry Sir, mujhe samajh nahi aaya.");
                }

            } catch (err) {
                console.error("Error:", err);
                statusText.innerText = "Error: " + err.message;
                aiReply.innerText = "Sir, connection mein kuch dikkat hai.";
                speak("Sir, connection mein kuch dikkat hai.");
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Listening Sir...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "You: " + transcript;

                // Local Command
                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Sir, abhi waqt ho raha hai ${time}`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
        /* 3D Liquid Orb Section */
        .orb-wrapper {
            position: relative; width: 350px; height: 350px;
            display: flex; justify-content: center; align-items: center;
        }
        .orb {
            width: 250px; height: 250px;
            background: linear-gradient(135deg, #4facfe, #00f2fe, #7028e4, #fb5e8b);
            background-size: 200% 200%; border-radius: 50%;
            filter: blur(2px); z-index: 2;
            animation: morph 8s ease-in-out infinite, gradientMove 10s infinite;
            box-shadow: inset -15px -15px 50px rgba(0,0,0,0.7), 0 0 60px rgba(79, 172, 254, 0.2);
            transition: all 0.5s cubic-bezier(0.175, 0.885, 0.32, 1.275);
        }

        @keyframes morph {
            0%, 100% { border-radius: 42% 58% 70% 30% / 45% 45% 55% 55%; }
            33% { border-radius: 70% 30% 46% 54% / 30% 39% 61% 70%; }
            66% { border-radius: 50% 50% 34% 66% / 56% 68% 32% 44%; }
        }
        @keyframes gradientMove { 0% {background-position: 0% 50%;} 50% {background-position: 100% 50%;} 100% {background-position: 0% 50%;} }

        /* Text Display Area */
        .content { text-align: center; max-width: 700px; z-index: 10; }
        #status-text { font-size: 24px; font-weight: 300; line-height: 1.4; color: #fff; }
        #ai-reply { color: var(--primary); font-size: 18px; margin-top: 15px; min-height: 24px; }

        /* Bottom Control Bar */
        .bottom-nav {
            width: 100%; max-width: 500px;
            display: flex; justify-content: space-around; align-items: center;
            margin-bottom: 30px;
        }
        .icon-btn {
            background: rgba(255, 255, 255, 0.05); border: 1px solid rgba(255,255,255,0.1);
            width: 65px; height: 65px; border-radius: 20px;
            color: white; font-size: 22px; cursor: pointer; backdrop-filter: blur(10px);
        }

        /* Mic Button & Ripple */
        .mic-box { position: relative; display: flex; justify-content: center; align-items: center; }
        .mic-btn {
            width: 95px; height: 95px; background: var(--primary);
            border: none; border-radius: 50%; font-size: 35px;
            color: black; cursor: pointer; z-index: 5;
            box-shadow: 0 10px 40px rgba(193, 255, 61, 0.5);
        }
        .pulse { position: absolute; width: 95px; height: 95px; border: 3px solid var(--primary); border-radius: 50%; opacity: 0; pointer-events: none; }

        /* Active State Effects */
        .listening .pulse { animation: ripple 1.5s infinite; }
        .listening .orb { transform: scale(1.3); filter: blur(15px) brightness(1.2); }
        .processing .orb { animation: morph 1s infinite alternate; filter: hue-rotate(90deg); }

        @keyframes ripple { 0% { transform: scale(1); opacity: 0.8; } 100% { transform: scale(2.2); opacity: 0; } }

    </style>
</head>
<body>

    <div class="app-container" id="mainApp">
        <div class="ai-badge">AI BUDDY ONLINE</div>

        <div class="orb-wrapper">
            <div class="orb" id="orb"></div>
        </div>

        <div class="content">
            <p id="status-text">Mic par click karke kuch bhi puchein...</p>
            <p id="ai-reply"></p>
        </div>

        <div class="bottom-nav">
            <button class="icon-btn"><i class="fa-solid fa-keyboard"></i></button>
            <div class="mic-box" id="micWrapper">
                <div class="pulse"></div>
                <button class="mic-btn" id="startBtn"><i class="fa-solid fa-microphone"></i></button>
            </div>
            <button class="icon-btn"><i class="fa-solid fa-xmark"></i></button>
        </div>
    </div>

    <script>
        // Updated API Key
        const API_KEY = "AIzaSyAI-ozKUZaQTnEZ2t5wVa4PXODTSwGTbkQ";
        
        const startBtn = document.getElementById('startBtn');
        const micWrapper = document.getElementById('micWrapper');
        const statusText = document.getElementById('status-text');
        const aiReply = document.getElementById('ai-reply');
        const mainApp = document.getElementById('mainApp');

        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        let recognition;

        if (SpeechRecognition) {
            recognition = new SpeechRecognition();
            recognition.lang = 'hi-IN'; // Uses Hinglish mix if supported
        } else {
            alert("Browser Mic support nahi karta. Chrome use karein.");
        }

        // --- Human-Like Voice Logic ---
        function speak(text) {
            window.speechSynthesis.cancel();
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            // Try to find a Hindi voice, else fallback
            const hindiVoice = voices.find(v => v.lang.includes('hi'));
            if (hindiVoice) utterance.voice = hindiVoice;
            utterance.rate = 1.0;
            window.speechSynthesis.speak(utterance);
        }

        // --- Gemini AI Logic with Better Error Handling ---
        async function getGeminiResponse(prompt) {
            mainApp.classList.add('processing');
            statusText.innerText = "Soch raha hoon...";

            // "Human-like" Persona Prompt
            const systemPrompt = `You are a friendly Indian friend. 
            Reply in casual Hinglish (Hindi + English mix). 
            Be funny, short, and natural. Don't be robotic. 
            User said: "${prompt}"`;

            try {
                const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({
                        contents: [{ parts: [{ text: systemPrompt }] }]
                    })
                });

                const data = await response.json();

                // Check for API Errors explicitly
                if (!response.ok) {
                    let errorMsg = data.error ? data.error.message : "API Error";
                    throw new Error(errorMsg);
                }

                if (data.candidates && data.candidates[0].content) {
                    const text = data.candidates[0].content.parts[0].text;
                    aiReply.innerText = text;
                    speak(text);
                } else {
                    aiReply.innerText = "Samajh nahi aaya, dubara bolo?";
                    speak("Samajh nahi aaya, dubara bolo?");
                }

            } catch (err) {
                console.error("Gemini Error:", err);
                // Show EXACT error to user
                if (err.message.includes("API key not valid")) {
                    statusText.innerText = "Error: Invalid API Key. Nayi key banayein.";
                    aiReply.innerText = "Ye API key kaam nahi kar rahi. Google AI Studio se nayi key lelo.";
                    speak("API key galat hai dost.");
                } else {
                    statusText.innerText = "Error: " + err.message;
                    aiReply.innerText = "Connection issue ya API error hai.";
                }
            }
            mainApp.classList.remove('processing');
        }

        startBtn.addEventListener('click', () => {
            if(recognition) {
                try {
                    recognition.start();
                    micWrapper.classList.add('listening');
                    statusText.innerText = "Sun raha hoon...";
                    aiReply.innerText = "";
                } catch(e) { console.log("Mic restart"); }
            }
        });

        if (recognition) {
            recognition.onresult = (event) => {
                micWrapper.classList.remove('listening');
                const transcript = event.results[0][0].transcript;
                statusText.innerText = "Aap: " + transcript;

                // Handle basic local commands
                if(transcript.toLowerCase().includes('time') || transcript.includes('samay')) {
                    const time = new Date().toLocaleTimeString('hi-IN', {hour:'2-digit', minute:'2-digit'});
                    const msg = `Bhai abhi ${time} baj rahe hain.`;
                    aiReply.innerText = msg;
                    speak(msg);
                } else {
                    getGeminiResponse(transcript);
                }
            };

            recognition.onerror = (e) => {
                micWrapper.classList.remove('listening');
                statusText.innerText = "Mic Error: " + e.error;
            };

            recognition.onspeechend = () => {
                recognition.stop();
                micWrapper.classList.remove('listening');
            };
        }

        // Voice loader
        window.speechSynthesis.onvoiceschanged = () => window.speechSynthesis.getVoices();

    </script>
</body>
</html>
